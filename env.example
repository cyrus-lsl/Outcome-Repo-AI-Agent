# LLM Configuration
# The app will automatically try local Ollama first, then fall back to your configured LLM

# Recommended: Use local Ollama (install from https://ollama.com)
# No configuration needed if Ollama is running - it will auto-detect

# Optional: Configure a cloud LLM fallback (for when Ollama is not running)
# Example with OpenAI:
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4o-mini
# LLM_API_KEY=your_openai_api_key_here

# Example with Azure OpenAI:
# LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# LLM_MODEL=gpt-4
# LLM_API_KEY=your_azure_api_key_here

# If not configured, the app requires Ollama to be running

# File Configuration
# EXCEL_FILE_PATH=measurement_instruments.xlsx
# EXCEL_SHEET_NAME=Measurement Instruments

# Application Settings
# MAX_RESULTS=8
# MAX_QUERY_LENGTH=500
# CACHE_TTL=3600

# Semantic Search Settings
# SEMANTIC_SEARCH_ENABLED=true
# SEMANTIC_MODEL=all-MiniLM-L6-v2
# SEMANTIC_THRESHOLD=0.1

# Performance Settings
# ENABLE_CACHING=true

